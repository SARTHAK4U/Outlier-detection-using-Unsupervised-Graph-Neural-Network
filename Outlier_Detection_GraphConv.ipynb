{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtTSE5nj5pMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9163e40a-f0e6-455e-b00e-256c27006d85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.1+cu116.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.1%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.1+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.1+cu116.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.17%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-sparse) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy->torch-sparse) (1.22.4)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.17+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.1+cu116.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_cluster-1.6.1%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-cluster) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy->torch-cluster) (1.22.4)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.1+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-yk8imaju\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-yk8imaju\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 85559709322b698c0575efe5043fa3c147375cf9\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.9/dist-packages (from torch_geometric==2.4.0) (3.0.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch_geometric==2.4.0) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from torch_geometric==2.4.0) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torch_geometric==2.4.0) (4.65.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.9/dist-packages (from torch_geometric==2.4.0) (5.9.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torch_geometric==2.4.0) (2.27.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch_geometric==2.4.0) (3.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch_geometric==2.4.0) (1.22.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch_geometric==2.4.0) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torch_geometric==2.4.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torch_geometric==2.4.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torch_geometric==2.4.0) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torch_geometric==2.4.0) (2.0.12)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch_geometric==2.4.0) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch_geometric==2.4.0) (3.1.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.4.0-py3-none-any.whl size=915409 sha256=e88de7a5c68975cbf193c491622fdb25ff6159ed31e70509b0fac2d9717d9e79\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-l795ydra/wheels/e5/8a/bc/10228fa47bb01dd916740a9102c063c4e363e7dac6d55dba4a\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n",
            "rm: cannot remove 'vertebral.mat': No such file or directory\n",
            "rm: cannot remove 'wine.mat': No such file or directory\n",
            "rm: cannot remove 'pima.mat': No such file or directory\n",
            "rm: cannot remove 'ionosphere.mat': No such file or directory\n",
            "rm: cannot remove 'wbc.mat': No such file or directory\n",
            "rm: cannot remove 'glass.mat': No such file or directory\n",
            "rm: cannot remove 'vowels.mat': No such file or directory\n",
            "rm: cannot remove 'letter.mat': No such file or directory\n",
            "--2023-04-02 14:14:43--  https://www.dropbox.com/s/5kuqb387sgvwmrb/vertebral.mat\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/5kuqb387sgvwmrb/vertebral.mat [following]\n",
            "--2023-04-02 14:14:43--  https://www.dropbox.com/s/raw/5kuqb387sgvwmrb/vertebral.mat\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc65ec41eef91fe0f38c04194c4b.dl.dropboxusercontent.com/cd/0/inline/B5ZQ5P-DycFsbEvJhrR8yAyhWpdroxy5bIqdlL3-ydELGf2BcPm55k4rLpn9dErYsdguSxztb_N7mZr6kLYbMvdQm55HC-Lp7J6ERYtNCiANEIRuOfbeioWmOk0v_6PpVnxfSDjfLX6_SSW57POpq6bVgrCJYcX2ngTMSbiphVMZLw/file# [following]\n",
            "--2023-04-02 14:14:44--  https://uc65ec41eef91fe0f38c04194c4b.dl.dropboxusercontent.com/cd/0/inline/B5ZQ5P-DycFsbEvJhrR8yAyhWpdroxy5bIqdlL3-ydELGf2BcPm55k4rLpn9dErYsdguSxztb_N7mZr6kLYbMvdQm55HC-Lp7J6ERYtNCiANEIRuOfbeioWmOk0v_6PpVnxfSDjfLX6_SSW57POpq6bVgrCJYcX2ngTMSbiphVMZLw/file\n",
            "Resolving uc65ec41eef91fe0f38c04194c4b.dl.dropboxusercontent.com (uc65ec41eef91fe0f38c04194c4b.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6027:15::a27d:480f\n",
            "Connecting to uc65ec41eef91fe0f38c04194c4b.dl.dropboxusercontent.com (uc65ec41eef91fe0f38c04194c4b.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B5bqB0tVwphw2uKxKe6VGg6v4437_46-bnQ9Qd9R1n8dEFfm6Hcuxp82hGxJo9hA1ns0aqRVUES4o77r4M6TYuSeoNX_oa6XpKw_CSFhC6XjyiRJGg_7OJ2eBEIagEW1_j4sns4e1VJEoo-cBgWm3LnOLFT5Db4LTI0Vwj4YXgFIVsSqeWB4Ul6a1w4iQ950sI--wk1ipLofypCbf-5gx6A-QK_KkoKZDNQdD8LRFVCb7Y1yzRCGxs_rYNbjy96t7e7Et96b16blKtLmeWvsCMjkQyTAABBpV_K-nfxae4H8KgSUb9vHodrSkM2ELqVqyVh25oua_4OqtLyMCWcG0jwTVSuCbyQcYFQlIl1Z4KFAmvOJbL7xg4Cq-KHp4UOSu8nSF1iNMDgW67qnGAxnxYM5XmeaHumkkWRIL9_lUEbCEQ/file [following]\n",
            "--2023-04-02 14:14:44--  https://uc65ec41eef91fe0f38c04194c4b.dl.dropboxusercontent.com/cd/0/inline2/B5bqB0tVwphw2uKxKe6VGg6v4437_46-bnQ9Qd9R1n8dEFfm6Hcuxp82hGxJo9hA1ns0aqRVUES4o77r4M6TYuSeoNX_oa6XpKw_CSFhC6XjyiRJGg_7OJ2eBEIagEW1_j4sns4e1VJEoo-cBgWm3LnOLFT5Db4LTI0Vwj4YXgFIVsSqeWB4Ul6a1w4iQ950sI--wk1ipLofypCbf-5gx6A-QK_KkoKZDNQdD8LRFVCb7Y1yzRCGxs_rYNbjy96t7e7Et96b16blKtLmeWvsCMjkQyTAABBpV_K-nfxae4H8KgSUb9vHodrSkM2ELqVqyVh25oua_4OqtLyMCWcG0jwTVSuCbyQcYFQlIl1Z4KFAmvOJbL7xg4Cq-KHp4UOSu8nSF1iNMDgW67qnGAxnxYM5XmeaHumkkWRIL9_lUEbCEQ/file\n",
            "Reusing existing connection to uc65ec41eef91fe0f38c04194c4b.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4891 (4.8K) [application/octet-stream]\n",
            "Saving to: ‘vertebral.mat’\n",
            "\n",
            "vertebral.mat       100%[===================>]   4.78K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-02 14:14:45 (842 MB/s) - ‘vertebral.mat’ saved [4891/4891]\n",
            "\n",
            "--2023-04-02 14:14:45--  https://www.dropbox.com/s/uvjaudt2uto7zal/wine.mat\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/uvjaudt2uto7zal/wine.mat [following]\n",
            "--2023-04-02 14:14:45--  https://www.dropbox.com/s/raw/uvjaudt2uto7zal/wine.mat\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc6c7f16ed9a4b89a484498cf5f7.dl.dropboxusercontent.com/cd/0/inline/B5abPCKW9TKW7xjyeFBoUW4myBzfCphKv1zIK-buwUiCNNuqiiAt9A1_p9ZibQ4sMCfhyr9lZcNBNtHx0_a4Vt34850SNZA-YdrxYqQE3fodJcgXyR-7QS0_Jj129cM50PMBdeukO8jzJe59JQ7VZ_2NgBoG-qbnsXSer4EDWTubaA/file# [following]\n",
            "--2023-04-02 14:14:45--  https://uc6c7f16ed9a4b89a484498cf5f7.dl.dropboxusercontent.com/cd/0/inline/B5abPCKW9TKW7xjyeFBoUW4myBzfCphKv1zIK-buwUiCNNuqiiAt9A1_p9ZibQ4sMCfhyr9lZcNBNtHx0_a4Vt34850SNZA-YdrxYqQE3fodJcgXyR-7QS0_Jj129cM50PMBdeukO8jzJe59JQ7VZ_2NgBoG-qbnsXSer4EDWTubaA/file\n",
            "Resolving uc6c7f16ed9a4b89a484498cf5f7.dl.dropboxusercontent.com (uc6c7f16ed9a4b89a484498cf5f7.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:601a:15::a27d:70f\n",
            "Connecting to uc6c7f16ed9a4b89a484498cf5f7.dl.dropboxusercontent.com (uc6c7f16ed9a4b89a484498cf5f7.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B5aIFjgReNFOrRxs67SGFr0dpelvPx_C3B2NFR5_MMU2YpyTepD7JR7uYDDpqMy5ZWLzO1HQcmR1srl7WtziEv4HI47u_C3XJwSRA7BcwXKsTXzKty7arQPxyZWQWvGQtueVYpQSELixdJ7oQ6SjhTovqUaRVa9dtaJSUaLWamZD86POc_ch1SXrbM8ZE5Ad3iSP6YuniaBH30hWzzxcyWAjK6Ymn_SQAZmTIDKIovuDuyixzF6Dsgb05JniYXfVYlzUSC283LwWlUO5RyXSMABBilVVJaL5RoNEQsWx8W8qM8urz2M-KUDxw_zJRlTzRCajFTTA9u2tlXTRiGxSFKadjUTbV4UKPUADKRw9bOYanobrZqrAkiegakqcdBAgeTgWIzzjspbMqxEeYjCJ71kaBUOAhF745j9VGV6-2OnFhA/file [following]\n",
            "--2023-04-02 14:14:46--  https://uc6c7f16ed9a4b89a484498cf5f7.dl.dropboxusercontent.com/cd/0/inline2/B5aIFjgReNFOrRxs67SGFr0dpelvPx_C3B2NFR5_MMU2YpyTepD7JR7uYDDpqMy5ZWLzO1HQcmR1srl7WtziEv4HI47u_C3XJwSRA7BcwXKsTXzKty7arQPxyZWQWvGQtueVYpQSELixdJ7oQ6SjhTovqUaRVa9dtaJSUaLWamZD86POc_ch1SXrbM8ZE5Ad3iSP6YuniaBH30hWzzxcyWAjK6Ymn_SQAZmTIDKIovuDuyixzF6Dsgb05JniYXfVYlzUSC283LwWlUO5RyXSMABBilVVJaL5RoNEQsWx8W8qM8urz2M-KUDxw_zJRlTzRCajFTTA9u2tlXTRiGxSFKadjUTbV4UKPUADKRw9bOYanobrZqrAkiegakqcdBAgeTgWIzzjspbMqxEeYjCJ71kaBUOAhF745j9VGV6-2OnFhA/file\n",
            "Reusing existing connection to uc6c7f16ed9a4b89a484498cf5f7.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4078 (4.0K) [application/octet-stream]\n",
            "Saving to: ‘wine.mat’\n",
            "\n",
            "wine.mat            100%[===================>]   3.98K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-02 14:14:46 (903 MB/s) - ‘wine.mat’ saved [4078/4078]\n",
            "\n",
            "--2023-04-02 14:14:46--  https://www.dropbox.com/s/mvlwu7p0nyk2a2r/pima.mat\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/mvlwu7p0nyk2a2r/pima.mat [following]\n",
            "--2023-04-02 14:14:46--  https://www.dropbox.com/s/raw/mvlwu7p0nyk2a2r/pima.mat\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc4ec3b3f9ab40b5882ee7b86786.dl.dropboxusercontent.com/cd/0/inline/B5aQtQ-3phCkFPA_RWADIP145L0JE-uQsUB8TMrtNp96htCEVK7rY9QO4iwD7GXgZmZzLtCAyVOyNtFfQaKHzZ46w8evbPYEeWijLE2fb5-uRn0GXw0pxKZCOtbcdFX6F1MlbFzi4hY4sXiMfoDnFSamXIo8i-f1-ACl_a_hrTyGVA/file# [following]\n",
            "--2023-04-02 14:14:47--  https://uc4ec3b3f9ab40b5882ee7b86786.dl.dropboxusercontent.com/cd/0/inline/B5aQtQ-3phCkFPA_RWADIP145L0JE-uQsUB8TMrtNp96htCEVK7rY9QO4iwD7GXgZmZzLtCAyVOyNtFfQaKHzZ46w8evbPYEeWijLE2fb5-uRn0GXw0pxKZCOtbcdFX6F1MlbFzi4hY4sXiMfoDnFSamXIo8i-f1-ACl_a_hrTyGVA/file\n",
            "Resolving uc4ec3b3f9ab40b5882ee7b86786.dl.dropboxusercontent.com (uc4ec3b3f9ab40b5882ee7b86786.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6021:15::a27d:410f\n",
            "Connecting to uc4ec3b3f9ab40b5882ee7b86786.dl.dropboxusercontent.com (uc4ec3b3f9ab40b5882ee7b86786.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B5b9NerOV6RdMopq0GmwXO2c6RWVwIhd0J-FZBIcyV8EmwjQa3XSOw490h7nWum-2WDDg3lBAiw0eNwmxVKJqUOGzP_xxZNxELbv_4hWWDzXVcCXJt0OxM09XA3WWPKsG7CXZkJPtGP3MESOzAPcUXFF6vdYNVbqQFvUrkwsCAI9hQbK2_eKzEFw9knXljwHXnF-RAB_N2tKS3KcBh14qMQCu4lJuP-QCW46UhYT2Bm4EgjEJzSZtaO5dz3ttUS-u6dUp9_MEKZDv1I24zXREJmYZv4CIBKyz1nUdRXl0P4ALKXFMHGmdvtOjwbbebZdamzkMKG3qrL-3zmAvf9fi-uJ6b9ywA41lAhvCkUt5TOLHpvj2YjuHORW_JQAGuGaIGiw9Tgy9n03aDH9JLsH-BPHEsQQuJMhYeA8pA9Rru_xEw/file [following]\n",
            "--2023-04-02 14:14:47--  https://uc4ec3b3f9ab40b5882ee7b86786.dl.dropboxusercontent.com/cd/0/inline2/B5b9NerOV6RdMopq0GmwXO2c6RWVwIhd0J-FZBIcyV8EmwjQa3XSOw490h7nWum-2WDDg3lBAiw0eNwmxVKJqUOGzP_xxZNxELbv_4hWWDzXVcCXJt0OxM09XA3WWPKsG7CXZkJPtGP3MESOzAPcUXFF6vdYNVbqQFvUrkwsCAI9hQbK2_eKzEFw9knXljwHXnF-RAB_N2tKS3KcBh14qMQCu4lJuP-QCW46UhYT2Bm4EgjEJzSZtaO5dz3ttUS-u6dUp9_MEKZDv1I24zXREJmYZv4CIBKyz1nUdRXl0P4ALKXFMHGmdvtOjwbbebZdamzkMKG3qrL-3zmAvf9fi-uJ6b9ywA41lAhvCkUt5TOLHpvj2YjuHORW_JQAGuGaIGiw9Tgy9n03aDH9JLsH-BPHEsQQuJMhYeA8pA9Rru_xEw/file\n",
            "Reusing existing connection to uc4ec3b3f9ab40b5882ee7b86786.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11320 (11K) [application/octet-stream]\n",
            "Saving to: ‘pima.mat’\n",
            "\n",
            "pima.mat            100%[===================>]  11.05K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-02 14:14:48 (208 MB/s) - ‘pima.mat’ saved [11320/11320]\n",
            "\n",
            "--2023-04-02 14:14:48--  https://www.dropbox.com/s/lpn4z73fico4uup/ionosphere.mat\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/lpn4z73fico4uup/ionosphere.mat [following]\n",
            "--2023-04-02 14:14:48--  https://www.dropbox.com/s/raw/lpn4z73fico4uup/ionosphere.mat\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc474ede031782c43a1fd756e082.dl.dropboxusercontent.com/cd/0/inline/B5ZT4C5F_m3B2vM1L1ZCrrXqmqQ_dv5O3q2uCAKEwwAoQyoIc6x3WM6fmHecSJo7hrCnY9P69W3lMj4MWc0qPr34funhMnCWfmFX-kwESeMwW4sFTdZF24-9CMObe6oVQFWjpZ7QoY58kApOVXyzHwifqemCb3xqj-04NXahEYtJ3w/file# [following]\n",
            "--2023-04-02 14:14:48--  https://uc474ede031782c43a1fd756e082.dl.dropboxusercontent.com/cd/0/inline/B5ZT4C5F_m3B2vM1L1ZCrrXqmqQ_dv5O3q2uCAKEwwAoQyoIc6x3WM6fmHecSJo7hrCnY9P69W3lMj4MWc0qPr34funhMnCWfmFX-kwESeMwW4sFTdZF24-9CMObe6oVQFWjpZ7QoY58kApOVXyzHwifqemCb3xqj-04NXahEYtJ3w/file\n",
            "Resolving uc474ede031782c43a1fd756e082.dl.dropboxusercontent.com (uc474ede031782c43a1fd756e082.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6021:15::a27d:410f\n",
            "Connecting to uc474ede031782c43a1fd756e082.dl.dropboxusercontent.com (uc474ede031782c43a1fd756e082.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B5bHj253zgw3wb8uE0MY0F6nlHa49gjdr6uXBUiqcGnC5R4m7MdWSnrZDHsZsrhBcCYtBQEs8JDWSypmzurGBcD1zcXtZliDyl3DFXEO3D5HURthkSfoTL5ThBaQDGwZBka4BPZ8vfMp7njSxO_atscOirKNsXxjV8IZzFXewaSG9-dWzAtRua1X0DheRCqUIOnjVpWdt2wdbngy0DLhYSYR9jaFfO5MK3bL9lZSi-YP7f5D1SE4Jnrgs5j3KZftQ9QwQBTxssK0aV-ZSn7n37DavSgPUiNf-d3EPCe9Ibm1fHHFKOHa5T0hKpA1VFwYJV6pdIwdpGhm_9gWGyopJGwXnnkqUeXv6e4knYabNZ4HUISBGwG2UdUTOif3xpJH5pqXeOwKpVfOR-N1Zog2DYGAvyV5paq9uKBBkIJbVwRBOg/file [following]\n",
            "--2023-04-02 14:14:49--  https://uc474ede031782c43a1fd756e082.dl.dropboxusercontent.com/cd/0/inline2/B5bHj253zgw3wb8uE0MY0F6nlHa49gjdr6uXBUiqcGnC5R4m7MdWSnrZDHsZsrhBcCYtBQEs8JDWSypmzurGBcD1zcXtZliDyl3DFXEO3D5HURthkSfoTL5ThBaQDGwZBka4BPZ8vfMp7njSxO_atscOirKNsXxjV8IZzFXewaSG9-dWzAtRua1X0DheRCqUIOnjVpWdt2wdbngy0DLhYSYR9jaFfO5MK3bL9lZSi-YP7f5D1SE4Jnrgs5j3KZftQ9QwQBTxssK0aV-ZSn7n37DavSgPUiNf-d3EPCe9Ibm1fHHFKOHa5T0hKpA1VFwYJV6pdIwdpGhm_9gWGyopJGwXnnkqUeXv6e4knYabNZ4HUISBGwG2UdUTOif3xpJH5pqXeOwKpVfOR-N1Zog2DYGAvyV5paq9uKBBkIJbVwRBOg/file\n",
            "Reusing existing connection to uc474ede031782c43a1fd756e082.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58517 (57K) [application/octet-stream]\n",
            "Saving to: ‘ionosphere.mat’\n",
            "\n",
            "ionosphere.mat      100%[===================>]  57.15K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2023-04-02 14:14:49 (9.37 MB/s) - ‘ionosphere.mat’ saved [58517/58517]\n",
            "\n",
            "--2023-04-02 14:14:49--  https://www.dropbox.com/s/ebz9v9kdnvykzcb/wbc.mat\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/ebz9v9kdnvykzcb/wbc.mat [following]\n",
            "--2023-04-02 14:14:49--  https://www.dropbox.com/s/raw/ebz9v9kdnvykzcb/wbc.mat\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc73193f5e04700210ca07a2f53c.dl.dropboxusercontent.com/cd/0/inline/B5ZvCt6S5fcfSkyvBjUgjAoB4bIJSf1HYBOYN7an8D0O3wE15B8EK6nJTEQuRrbGt3-qUCXQzpBi7KgBz-Ncj3GuijHwRZaYGYR0sTeMrNlpvstTtqALyeE_L2mPqEP25YwY8rcruMT3M6TQhYx0dlLMqX7E-Xor5ra2zOf1pwQW3Q/file# [following]\n",
            "--2023-04-02 14:14:50--  https://uc73193f5e04700210ca07a2f53c.dl.dropboxusercontent.com/cd/0/inline/B5ZvCt6S5fcfSkyvBjUgjAoB4bIJSf1HYBOYN7an8D0O3wE15B8EK6nJTEQuRrbGt3-qUCXQzpBi7KgBz-Ncj3GuijHwRZaYGYR0sTeMrNlpvstTtqALyeE_L2mPqEP25YwY8rcruMT3M6TQhYx0dlLMqX7E-Xor5ra2zOf1pwQW3Q/file\n",
            "Resolving uc73193f5e04700210ca07a2f53c.dl.dropboxusercontent.com (uc73193f5e04700210ca07a2f53c.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6027:15::a27d:480f\n",
            "Connecting to uc73193f5e04700210ca07a2f53c.dl.dropboxusercontent.com (uc73193f5e04700210ca07a2f53c.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B5YreTHpo-6Fh3J_NAlotnDkhZihOCjPm6ApCf1kAkjVE47cFmxBw9HpzJg5DaH9Qv_YHzhYkMJ9xcJoH660GEPQUCWXA0ES_NvIt249fMe7x94Eiv9JIOQporjEKrEtXP3Rr8cToy8NPYgkabMCha4SKWed33sAwSWTDCCFcEmiRsVUQ_OIvrve5BkZ0eu0_LTVg_btXir-1fZLDbuIhbNVyaqxVYZ7QlYEWBA1FAvSnnm0UNvKtk4dabx85EtolsMg5eJbbQg9T0Ka2CLhg5lBF4vjj1iK8xK5Mu8gASYdO6T5ew1wUU-zHmRxpMLEkn4zmGh9TP0BK2Bg0AP7KC6zK1ArkFFCO6xdeaqUFvbBxB_OsrA6e4G-18OeyOQ46xoFaQiiOAudpi0MeX_N_FMDsFOLH9-6AggJSc0DGDlzrg/file [following]\n",
            "--2023-04-02 14:14:51--  https://uc73193f5e04700210ca07a2f53c.dl.dropboxusercontent.com/cd/0/inline2/B5YreTHpo-6Fh3J_NAlotnDkhZihOCjPm6ApCf1kAkjVE47cFmxBw9HpzJg5DaH9Qv_YHzhYkMJ9xcJoH660GEPQUCWXA0ES_NvIt249fMe7x94Eiv9JIOQporjEKrEtXP3Rr8cToy8NPYgkabMCha4SKWed33sAwSWTDCCFcEmiRsVUQ_OIvrve5BkZ0eu0_LTVg_btXir-1fZLDbuIhbNVyaqxVYZ7QlYEWBA1FAvSnnm0UNvKtk4dabx85EtolsMg5eJbbQg9T0Ka2CLhg5lBF4vjj1iK8xK5Mu8gASYdO6T5ew1wUU-zHmRxpMLEkn4zmGh9TP0BK2Bg0AP7KC6zK1ArkFFCO6xdeaqUFvbBxB_OsrA6e4G-18OeyOQ46xoFaQiiOAudpi0MeX_N_FMDsFOLH9-6AggJSc0DGDlzrg/file\n",
            "Reusing existing connection to uc73193f5e04700210ca07a2f53c.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 78408 (77K) [application/octet-stream]\n",
            "Saving to: ‘wbc.mat’\n",
            "\n",
            "wbc.mat             100%[===================>]  76.57K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2023-04-02 14:14:51 (9.54 MB/s) - ‘wbc.mat’ saved [78408/78408]\n",
            "\n",
            "--2023-04-02 14:14:51--  https://www.dropbox.com/s/iq3hjxw77gpbl7u/glass.mat\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/iq3hjxw77gpbl7u/glass.mat [following]\n",
            "--2023-04-02 14:14:51--  https://www.dropbox.com/s/raw/iq3hjxw77gpbl7u/glass.mat\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb80e2bdcb487594148c6c82ef0.dl.dropboxusercontent.com/cd/0/inline/B5aHWqnY6wQdESs982T9IqbbpNvvQLxqnSxcGCNobHhSgXTKRNxMrBXwoNWvgQqTPFGQ4N8jM4ptvgI-r_cceum0AJ4GL6MaJ_CAkB4JXGi206pYNNYLYiMQ0V0dsLsHeGSr9xcq97v0lLxf6KOJvG9beJNecE56jyYUYRjLPYASJA/file# [following]\n",
            "--2023-04-02 14:14:52--  https://ucb80e2bdcb487594148c6c82ef0.dl.dropboxusercontent.com/cd/0/inline/B5aHWqnY6wQdESs982T9IqbbpNvvQLxqnSxcGCNobHhSgXTKRNxMrBXwoNWvgQqTPFGQ4N8jM4ptvgI-r_cceum0AJ4GL6MaJ_CAkB4JXGi206pYNNYLYiMQ0V0dsLsHeGSr9xcq97v0lLxf6KOJvG9beJNecE56jyYUYRjLPYASJA/file\n",
            "Resolving ucb80e2bdcb487594148c6c82ef0.dl.dropboxusercontent.com (ucb80e2bdcb487594148c6c82ef0.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6022:15::a27d:420f\n",
            "Connecting to ucb80e2bdcb487594148c6c82ef0.dl.dropboxusercontent.com (ucb80e2bdcb487594148c6c82ef0.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B5Yw0SY-6rtFR29_JEkwnKlIw8vbXUSkEL0b-E6jG-c9bsaH7E63glchUHHoWXZlTtr4F0EdKrjsLVEAbKfIzDOocuYkoy3pURId6IgMzzRNctKp4ZTRsxw4pOoImeNoPtUMg9d2advgeYGDysLY7k8sVEFKDGJQM316oZ89JBMzEvvcGileumC_aM9VRQ5Kcz0qO9VaDynNuOqO5v3FYXmHxzLn90ibb8RPXMhLMAWGmpSwknWTQ9pOJxgJpa3l-4hmP4a7fhpOKGI6UHZBA2hPBPMVpjGw6nAdI1jT9riejH9SAGcUQNF0roSy21k0lRRzOgDLH5gbVPY96N7bh8peayst8sXSiDWpKIJ44E1-UfP3eBua-8Yq6BritlK6LEg-s3hwagOzUA8z3VjNcoHhD44wNYydBrGNVAyFlsbUNQ/file [following]\n",
            "--2023-04-02 14:14:53--  https://ucb80e2bdcb487594148c6c82ef0.dl.dropboxusercontent.com/cd/0/inline2/B5Yw0SY-6rtFR29_JEkwnKlIw8vbXUSkEL0b-E6jG-c9bsaH7E63glchUHHoWXZlTtr4F0EdKrjsLVEAbKfIzDOocuYkoy3pURId6IgMzzRNctKp4ZTRsxw4pOoImeNoPtUMg9d2advgeYGDysLY7k8sVEFKDGJQM316oZ89JBMzEvvcGileumC_aM9VRQ5Kcz0qO9VaDynNuOqO5v3FYXmHxzLn90ibb8RPXMhLMAWGmpSwknWTQ9pOJxgJpa3l-4hmP4a7fhpOKGI6UHZBA2hPBPMVpjGw6nAdI1jT9riejH9SAGcUQNF0roSy21k0lRRzOgDLH5gbVPY96N7bh8peayst8sXSiDWpKIJ44E1-UfP3eBua-8Yq6BritlK6LEg-s3hwagOzUA8z3VjNcoHhD44wNYydBrGNVAyFlsbUNQ/file\n",
            "Reusing existing connection to ucb80e2bdcb487594148c6c82ef0.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4967 (4.9K) [application/octet-stream]\n",
            "Saving to: ‘glass.mat’\n",
            "\n",
            "glass.mat           100%[===================>]   4.85K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-02 14:14:54 (856 MB/s) - ‘glass.mat’ saved [4967/4967]\n",
            "\n",
            "--2023-04-02 14:14:54--  https://www.dropbox.com/s/pa26odoq6atq9vx/vowels.mat\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/pa26odoq6atq9vx/vowels.mat [following]\n",
            "--2023-04-02 14:14:54--  https://www.dropbox.com/s/raw/pa26odoq6atq9vx/vowels.mat\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc03006538278fe41325201e561b.dl.dropboxusercontent.com/cd/0/inline/B5YEhQXYIcAHsWZ52WfhbS9ewFZ6H6hQWwBNSxXXosPVAbHKmSipH3KiMJF59G8NPRLVwXHm6L0MwdwbNZ7LjeVwwYDdWuB_KHe-ZCTmSPE2R1Y3GJzwrEybSEq44C6kW-qCYj4Xj1gZu2nceOqbLjwUX5u2VlsUoi83hDZKLzHu7w/file# [following]\n",
            "--2023-04-02 14:14:54--  https://uc03006538278fe41325201e561b.dl.dropboxusercontent.com/cd/0/inline/B5YEhQXYIcAHsWZ52WfhbS9ewFZ6H6hQWwBNSxXXosPVAbHKmSipH3KiMJF59G8NPRLVwXHm6L0MwdwbNZ7LjeVwwYDdWuB_KHe-ZCTmSPE2R1Y3GJzwrEybSEq44C6kW-qCYj4Xj1gZu2nceOqbLjwUX5u2VlsUoi83hDZKLzHu7w/file\n",
            "Resolving uc03006538278fe41325201e561b.dl.dropboxusercontent.com (uc03006538278fe41325201e561b.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6027:15::a27d:480f\n",
            "Connecting to uc03006538278fe41325201e561b.dl.dropboxusercontent.com (uc03006538278fe41325201e561b.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B5bZYqLpU3F_jBlu-xYU4j8uiM4vwplLIcX1VyuJdcGTQmzQ9NpNFA-z8IU-VKJt2nA_zJGRDBwau5YmFD0M5-XrO6uoVC7S1xGevhjk7xTvL7wSh56WBi9EXi2K8w1PaY3Tc_6BCVHIrk8frxzRkpRxC5y8RJlc8f8J7nHB30QvqBqs8DiGtNrEG3JoQXUS07FOny3p6mNBCyv-5fF8zsBGivh1rSzWO_3ipFtnya5Fbr-MXOGrtMo6AUOqEhpgZtUyL6cMFA41ooKOqOg0D8IAABG-ksgvL68ldZSe02TQywfRQZx4y2Qqrbx4yC9hCi_EMwMcjhVNfOUA58DlM9hsOD8CO6x9NvMOvVMUefeRVtOaD3xDDbOT9t4bn1lrGIbyd8P0vTFP5Vd5tk5Nguy9Z0jDMan1N7hUbD-CLqntSw/file [following]\n",
            "--2023-04-02 14:14:55--  https://uc03006538278fe41325201e561b.dl.dropboxusercontent.com/cd/0/inline2/B5bZYqLpU3F_jBlu-xYU4j8uiM4vwplLIcX1VyuJdcGTQmzQ9NpNFA-z8IU-VKJt2nA_zJGRDBwau5YmFD0M5-XrO6uoVC7S1xGevhjk7xTvL7wSh56WBi9EXi2K8w1PaY3Tc_6BCVHIrk8frxzRkpRxC5y8RJlc8f8J7nHB30QvqBqs8DiGtNrEG3JoQXUS07FOny3p6mNBCyv-5fF8zsBGivh1rSzWO_3ipFtnya5Fbr-MXOGrtMo6AUOqEhpgZtUyL6cMFA41ooKOqOg0D8IAABG-ksgvL68ldZSe02TQywfRQZx4y2Qqrbx4yC9hCi_EMwMcjhVNfOUA58DlM9hsOD8CO6x9NvMOvVMUefeRVtOaD3xDDbOT9t4bn1lrGIbyd8P0vTFP5Vd5tk5Nguy9Z0jDMan1N7hUbD-CLqntSw/file\n",
            "Reusing existing connection to uc03006538278fe41325201e561b.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 134107 (131K) [application/octet-stream]\n",
            "Saving to: ‘vowels.mat’\n",
            "\n",
            "vowels.mat          100%[===================>] 130.96K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-04-02 14:14:55 (12.7 MB/s) - ‘vowels.mat’ saved [134107/134107]\n",
            "\n",
            "--2023-04-02 14:14:55--  https://www.dropbox.com/s/rt9i95h9jywrtiy/letter.mat\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/rt9i95h9jywrtiy/letter.mat [following]\n",
            "--2023-04-02 14:14:56--  https://www.dropbox.com/s/raw/rt9i95h9jywrtiy/letter.mat\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucde133c6e9f3dfd28438f24fa4e.dl.dropboxusercontent.com/cd/0/inline/B5YvWnQVIojEZ8wdFy3t6x6bFtKuqTgbFRh7CJRP9zkvjQVZ0EII2ukKJGg9vLDRQvqUZQPO10PwxAqZY-IaCqYi68xjnlagjuNjbw7dEJhU7r2V50402rarx8FJ5bXDQQ2K424t75JMJiRuEJTH2KmjubLgMa0wfjp92Hakx_AXmg/file# [following]\n",
            "--2023-04-02 14:14:56--  https://ucde133c6e9f3dfd28438f24fa4e.dl.dropboxusercontent.com/cd/0/inline/B5YvWnQVIojEZ8wdFy3t6x6bFtKuqTgbFRh7CJRP9zkvjQVZ0EII2ukKJGg9vLDRQvqUZQPO10PwxAqZY-IaCqYi68xjnlagjuNjbw7dEJhU7r2V50402rarx8FJ5bXDQQ2K424t75JMJiRuEJTH2KmjubLgMa0wfjp92Hakx_AXmg/file\n",
            "Resolving ucde133c6e9f3dfd28438f24fa4e.dl.dropboxusercontent.com (ucde133c6e9f3dfd28438f24fa4e.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6027:15::a27d:480f\n",
            "Connecting to ucde133c6e9f3dfd28438f24fa4e.dl.dropboxusercontent.com (ucde133c6e9f3dfd28438f24fa4e.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B5b49tqU6oIy1krltDw-l8YVExIU2NhaiHLIjZUD_o8fJXUJho4B6JmL36FG2fxC3hCgn2M2eeI-apXlu3JLEi8bqMxk_jwmZhei9VfCO4ACiHnluohJjKzF6D3uIM2wlOiPPQfSMM9vL9r-jUTLdDWn0JPehNJhlKzA39-k75deMfI-oLV8WKLkjNRnvQ8No5HtOargUP76cOgi8FsPnSnTqV98dAfYoFeX3rbekRhclpGU6BDsvxsDC-1r7ZuxiX5liiXR9IhhO41QgXOazhSOyHb7TbsgwYyIuGqqviQxicSS5uKkgxMAPYval_57ihVZ6FBhzTWHeyXnFZYt153bOOq7OZKF1wlyGil_tx2k5bPPqW2wMcSqcmS0VV_bCx_EUasBS5SziaYaz9-x_QQrlnpr5maZYAfZT9zVTyrsiQ/file [following]\n",
            "--2023-04-02 14:14:56--  https://ucde133c6e9f3dfd28438f24fa4e.dl.dropboxusercontent.com/cd/0/inline2/B5b49tqU6oIy1krltDw-l8YVExIU2NhaiHLIjZUD_o8fJXUJho4B6JmL36FG2fxC3hCgn2M2eeI-apXlu3JLEi8bqMxk_jwmZhei9VfCO4ACiHnluohJjKzF6D3uIM2wlOiPPQfSMM9vL9r-jUTLdDWn0JPehNJhlKzA39-k75deMfI-oLV8WKLkjNRnvQ8No5HtOargUP76cOgi8FsPnSnTqV98dAfYoFeX3rbekRhclpGU6BDsvxsDC-1r7ZuxiX5liiXR9IhhO41QgXOazhSOyHb7TbsgwYyIuGqqviQxicSS5uKkgxMAPYval_57ihVZ6FBhzTWHeyXnFZYt153bOOq7OZKF1wlyGil_tx2k5bPPqW2wMcSqcmS0VV_bCx_EUasBS5SziaYaz9-x_QQrlnpr5maZYAfZT9zVTyrsiQ/file\n",
            "Reusing existing connection to ucde133c6e9f3dfd28438f24fa4e.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23146 (23K) [application/octet-stream]\n",
            "Saving to: ‘letter.mat’\n",
            "\n",
            "letter.mat          100%[===================>]  22.60K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2023-04-02 14:14:57 (6.44 MB/s) - ‘letter.mat’ saved [23146/23146]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "! rm -r vertebral.mat wine.mat pima.mat ionosphere.mat wbc.mat glass.mat vowels.mat letter.mat \n",
        "! wget https://www.dropbox.com/s/5kuqb387sgvwmrb/vertebral.mat\n",
        "! wget https://www.dropbox.com/s/uvjaudt2uto7zal/wine.mat\n",
        "! wget https://www.dropbox.com/s/mvlwu7p0nyk2a2r/pima.mat\n",
        "! wget https://www.dropbox.com/s/lpn4z73fico4uup/ionosphere.mat\n",
        "! wget https://www.dropbox.com/s/ebz9v9kdnvykzcb/wbc.mat\n",
        "! wget https://www.dropbox.com/s/iq3hjxw77gpbl7u/glass.mat\n",
        "! wget https://www.dropbox.com/s/pa26odoq6atq9vx/vowels.mat\n",
        "! wget https://www.dropbox.com/s/rt9i95h9jywrtiy/letter.mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRuft33E5P--"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch_geometric.nn.conv as gnn\n",
        "\n",
        "from sklearn.metrics import auc\n",
        "from torch_geometric.data import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeGrvpP7D4Yy"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0YD7-5HASyG"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(a, b):\n",
        "    a = a / np.sum(a ** 2) ** 0.5\n",
        "    b = b / np.sum(b ** 2) ** 0.5\n",
        "    return np.sum(a * b)\n",
        "    # return 1/(1+euclidean_distance(a, b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Le7uRuauYY1U"
      },
      "outputs": [],
      "source": [
        "def euclidean_distance(a, b):\n",
        "    dist = np.sum((a - b) ** 2) ** 0.5\n",
        "    return dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9cb3T1M5mzI",
        "outputId": "06dd2850-da3c-49a3-be6a-7095ab015cba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(378, 30) (378, 1)\n"
          ]
        }
      ],
      "source": [
        "data = sio.loadmat('wbc.mat')\n",
        "\n",
        "x = data['X'].astype(np.float32)\n",
        "y = data['y'].astype(np.float32)\n",
        "\n",
        "# x = x - np.mean(x, axis = 0)\n",
        "# x = x / np.std(x, axis = 0)\n",
        "\n",
        "ind = list(range(x.shape[0]))\n",
        "random.shuffle(ind)\n",
        "x, y = x[ind], y[ind]\n",
        "\n",
        "print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Edge selection based on euclidean distance\n",
        "# k = int(x.shape[0] // 40)\n",
        "k = 10\n",
        "edge_index = []\n",
        "edge_weights = []\n",
        "for i in range(x.shape[0]):\n",
        "    neighbours = []\n",
        "    for j in range(x.shape[0]):\n",
        "        similarity =  cosine_similarity(x[i], x[j])\n",
        "        neighbours.append([similarity, j])\n",
        "    neighbours.sort(reverse = True)\n",
        "    for ind in range(1, k + 1):\n",
        "        j = neighbours[ind][1]\n",
        "        similarity = neighbours[ind][0]\n",
        "        edge_index.append([j, i])\n",
        "        edge_weights.append(similarity)\n",
        "\n",
        "edge_index = np.array(edge_index).astype(np.int64)\n",
        "edge_index = edge_index.T\n",
        "print(edge_index.shape)\n",
        "\n",
        "edge_weights = np.array(edge_weights).astype(np.float32)\n",
        "print(edge_weights.shape)\n"
      ],
      "metadata": {
        "id": "_-p2B5dW7Fqu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2693b7f4-45cd-482c-c7f2-1201b8de0ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 3780)\n",
            "(3780,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Graph creation\n",
        "graph = Data(x = torch.tensor(x), edge_index = torch.tensor(edge_index), edge_attr=torch.tensor(edge_weights))\n",
        "graph = graph.to(device)\n",
        "display(graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "mooI8J14zscm",
        "outputId": "1fcbe12c-a119-4a64-99b7-1e020b1e974f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Data(x=[378, 30], edge_index=[2, 3780], edge_attr=[3780])"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8xY5vtfEBDi"
      },
      "outputs": [],
      "source": [
        "# Graph based model\n",
        "class GAE(torch.nn.Module):\n",
        "    def __init__(self, dim_in, dim_h, dim_out):\n",
        "        super().__init__()\n",
        "        self.p = 0.5\n",
        "        self.bn = torch.nn.BatchNorm1d(dim_in)\n",
        "        self.graph_conv1 = gnn.GraphConv(dim_h, dim_h) \n",
        "\n",
        "        # in_channels: The number of input channels for the graph convolution layer. \n",
        "        # This is typically equal to the number of features or attributes for each node in the graph.\n",
        "\n",
        "        # out_channels: The number of output channels for the graph convolution layer. \n",
        "        # This determines the number of features or attributes that will be output for each node in the graph.\n",
        "\n",
        "        self.graph_conv2 = gnn.GraphConv(dim_h, dim_h)\n",
        "        self.input = torch.nn.Linear(dim_in, dim_h)\n",
        "        self.output = torch.nn.Linear(dim_h, dim_out)\n",
        "\n",
        "    def forward(self, data):\n",
        "        h = data.x\n",
        "        h = self.bn(h)\n",
        "        h = self.input(h)\n",
        "        h = torch.relu(h)\n",
        "        h = self.graph_conv1(h, data.edge_index, data.edge_attr)\n",
        "        h = torch.relu(h)\n",
        "        layer_1_output = h\n",
        "        h = torch.nn.functional.dropout(h, p = self.p, training = self.training)\n",
        "        h = self.graph_conv2(h, data.edge_index, data.edge_attr)\n",
        "        h = torch.relu(h)\n",
        "        layer_2_output = h\n",
        "        h = (layer_1_output + layer_2_output) * 0.5\n",
        "        h = self.output(h)\n",
        "        return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnTUy_uqGc1G"
      },
      "outputs": [],
      "source": [
        "# Loss function\n",
        "def loss_function(embeddings, graph):\n",
        "    loss = embeddings - graph.x\n",
        "    loss = torch.sum(loss ** 2, axis = 1)\n",
        "    loss = torch.mean(loss ** 0.5)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTiujYemEBbt"
      },
      "outputs": [],
      "source": [
        "# AUC evaluation\n",
        "def evaluate(x, x_emb, y, plot = False):\n",
        "    ranking = []\n",
        "    for i in range(x.shape[0]):\n",
        "        distance = euclidean_distance(x[i], x_emb[i])\n",
        "        ranking.append([distance, y[i][0]])\n",
        "    ranking.sort(reverse = True)\n",
        "    tpr, fpr = [], []\n",
        "    positive = np.sum(y)\n",
        "    negative = x.shape[0] - np.sum(y)\n",
        "    for outlier_count in range(1, x.shape[0] + 1):\n",
        "        tp, fp = 0, 0\n",
        "        for i in range(outlier_count):\n",
        "            tp += ranking[i][-1]\n",
        "            fp += 1 - ranking[i][-1]\n",
        "        tpr.append(tp / positive)\n",
        "        fpr.append(fp / negative)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    if plot:\n",
        "        plt.plot(fpr, tpr)\n",
        "        plt.plot(fpr, fpr)\n",
        "        plt.grid()\n",
        "        plt.title('ROC AUC: %.3f' % (roc_auc))\n",
        "        plt.show()\n",
        "    else:\n",
        "        return roc_auc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim_h = graph.x.shape[1]\n",
        "model = GAE(graph.x.shape[1], dim_h, graph.x.shape[1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
        "\n",
        "best_roc = 0\n",
        "epochs = 500\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()  #model.train() is a method in PyTorch that sets the model in training mode. \n",
        "    #This means that the model will behave differently during training compared to evaluation or inference.\n",
        "    optimizer.zero_grad() #optimizer.zero_grad() is a method in PyTorch that sets the gradients of all parameters in the optimizer to zero. \n",
        "    #This is typically done before computing the gradients for a new batch of data during the training process of a neural network\n",
        "    embeddings = model(graph)\n",
        "    loss = loss_function(embeddings, graph)\n",
        "    loss.backward()\n",
        "    optimizer.step()#optimizer.step() is a method in PyTorch that is used to update \n",
        "    #the parameters of a neural network during the training process using an optimization algorithm.\n",
        "    if epoch % 10 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            x_emb = model(graph)\n",
        "            x_emb = x_emb.detach().numpy()  #The .detach() method is commonly used to extract a tensor from a larger computation graph\n",
        "            # and use it in a separate calculation or for checkpointing during training. \n",
        "            loss = loss.detach().numpy()\n",
        "            roc_auc = evaluate(x, x_emb, y, plot = False)      \n",
        "            print('Epoch: %2d \\t Loss: %.2f \\t ROC AUC: %.2f' % (epoch, loss, roc_auc))\n",
        "            best_roc = max(best_roc, roc_auc)\n",
        "print('\\nROC: %.2f' % best_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TftsUWvdr40A",
        "outputId": "4429a95c-cdf3-43e8-8cc0-2f05a075b0c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 \t Loss: 0.98 \t ROC AUC: 0.97\n",
            "Epoch: 20 \t Loss: 0.58 \t ROC AUC: 0.94\n",
            "Epoch: 30 \t Loss: 0.52 \t ROC AUC: 0.93\n",
            "Epoch: 40 \t Loss: 0.48 \t ROC AUC: 0.92\n",
            "Epoch: 50 \t Loss: 0.43 \t ROC AUC: 0.90\n",
            "Epoch: 60 \t Loss: 0.38 \t ROC AUC: 0.90\n",
            "Epoch: 70 \t Loss: 0.36 \t ROC AUC: 0.90\n",
            "Epoch: 80 \t Loss: 0.34 \t ROC AUC: 0.89\n",
            "Epoch: 90 \t Loss: 0.32 \t ROC AUC: 0.90\n",
            "Epoch: 100 \t Loss: 0.32 \t ROC AUC: 0.89\n",
            "Epoch: 110 \t Loss: 0.30 \t ROC AUC: 0.89\n",
            "Epoch: 120 \t Loss: 0.30 \t ROC AUC: 0.90\n",
            "Epoch: 130 \t Loss: 0.29 \t ROC AUC: 0.89\n",
            "Epoch: 140 \t Loss: 0.28 \t ROC AUC: 0.89\n",
            "Epoch: 150 \t Loss: 0.28 \t ROC AUC: 0.89\n",
            "Epoch: 160 \t Loss: 0.27 \t ROC AUC: 0.89\n",
            "Epoch: 170 \t Loss: 0.27 \t ROC AUC: 0.88\n",
            "Epoch: 180 \t Loss: 0.26 \t ROC AUC: 0.89\n",
            "Epoch: 190 \t Loss: 0.25 \t ROC AUC: 0.89\n",
            "Epoch: 200 \t Loss: 0.25 \t ROC AUC: 0.88\n",
            "Epoch: 210 \t Loss: 0.24 \t ROC AUC: 0.87\n",
            "Epoch: 220 \t Loss: 0.24 \t ROC AUC: 0.88\n",
            "Epoch: 230 \t Loss: 0.24 \t ROC AUC: 0.87\n",
            "Epoch: 240 \t Loss: 0.23 \t ROC AUC: 0.86\n",
            "Epoch: 250 \t Loss: 0.23 \t ROC AUC: 0.86\n",
            "Epoch: 260 \t Loss: 0.23 \t ROC AUC: 0.85\n",
            "Epoch: 270 \t Loss: 0.22 \t ROC AUC: 0.86\n",
            "Epoch: 280 \t Loss: 0.22 \t ROC AUC: 0.84\n",
            "Epoch: 290 \t Loss: 0.22 \t ROC AUC: 0.84\n",
            "Epoch: 300 \t Loss: 0.22 \t ROC AUC: 0.84\n",
            "Epoch: 310 \t Loss: 0.21 \t ROC AUC: 0.85\n",
            "Epoch: 320 \t Loss: 0.21 \t ROC AUC: 0.83\n",
            "Epoch: 330 \t Loss: 0.21 \t ROC AUC: 0.84\n",
            "Epoch: 340 \t Loss: 0.21 \t ROC AUC: 0.85\n",
            "Epoch: 350 \t Loss: 0.21 \t ROC AUC: 0.86\n",
            "Epoch: 360 \t Loss: 0.20 \t ROC AUC: 0.86\n",
            "Epoch: 370 \t Loss: 0.20 \t ROC AUC: 0.88\n",
            "Epoch: 380 \t Loss: 0.20 \t ROC AUC: 0.86\n",
            "Epoch: 390 \t Loss: 0.19 \t ROC AUC: 0.87\n",
            "Epoch: 400 \t Loss: 0.19 \t ROC AUC: 0.87\n",
            "Epoch: 410 \t Loss: 0.19 \t ROC AUC: 0.87\n",
            "Epoch: 420 \t Loss: 0.19 \t ROC AUC: 0.85\n",
            "Epoch: 430 \t Loss: 0.19 \t ROC AUC: 0.88\n",
            "Epoch: 440 \t Loss: 0.18 \t ROC AUC: 0.86\n",
            "Epoch: 450 \t Loss: 0.19 \t ROC AUC: 0.87\n",
            "Epoch: 460 \t Loss: 0.19 \t ROC AUC: 0.86\n",
            "Epoch: 470 \t Loss: 0.19 \t ROC AUC: 0.88\n",
            "Epoch: 480 \t Loss: 0.18 \t ROC AUC: 0.87\n",
            "Epoch: 490 \t Loss: 0.18 \t ROC AUC: 0.89\n",
            "Epoch: 500 \t Loss: 0.18 \t ROC AUC: 0.87\n",
            "\n",
            "ROC: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_TOluxTmKhY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0EUnhR-3KhiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-7v1T4yALXl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Wise Records"
      ],
      "metadata": {
        "id": "vZnutso4kkKp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset: wbc"
      ],
      "metadata": {
        "id": "uuExINqhtjFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# wbc :: k=10 :: norm=false\n",
        "dim_h = graph.x.shape[1]\n",
        "model = GAE(graph.x.shape[1], dim_h, graph.x.shape[1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.005)\n",
        "\n",
        "best_roc = 0\n",
        "epochs = 500\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    embeddings = model(graph)\n",
        "    loss = loss_function(embeddings, graph)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            x_emb = model(graph)\n",
        "            x_emb = x_emb.detach().numpy()\n",
        "            loss = loss.detach().numpy()\n",
        "            roc_auc = evaluate(x, x_emb, y, plot = False)      \n",
        "            print('Epoch: %2d \\t Loss: %.2f \\t ROC AUC: %.2f' % (epoch, loss, roc_auc))\n",
        "            best_roc = max(best_roc, roc_auc)\n",
        "print('\\nROC: %.2f' % best_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKZe6XHJKAn_",
        "outputId": "64921acc-101b-4f4e-aa8d-ba2e49de9d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 \t Loss: 1.11 \t ROC AUC: 0.98\n",
            "Epoch: 20 \t Loss: 0.66 \t ROC AUC: 0.98\n",
            "Epoch: 30 \t Loss: 0.55 \t ROC AUC: 0.95\n",
            "Epoch: 40 \t Loss: 0.50 \t ROC AUC: 0.93\n",
            "Epoch: 50 \t Loss: 0.46 \t ROC AUC: 0.90\n",
            "Epoch: 60 \t Loss: 0.43 \t ROC AUC: 0.87\n",
            "Epoch: 70 \t Loss: 0.41 \t ROC AUC: 0.87\n",
            "Epoch: 80 \t Loss: 0.38 \t ROC AUC: 0.87\n",
            "Epoch: 90 \t Loss: 0.37 \t ROC AUC: 0.86\n",
            "Epoch: 100 \t Loss: 0.35 \t ROC AUC: 0.83\n",
            "Epoch: 110 \t Loss: 0.34 \t ROC AUC: 0.87\n",
            "Epoch: 120 \t Loss: 0.33 \t ROC AUC: 0.88\n",
            "Epoch: 130 \t Loss: 0.31 \t ROC AUC: 0.86\n",
            "Epoch: 140 \t Loss: 0.31 \t ROC AUC: 0.87\n",
            "Epoch: 150 \t Loss: 0.30 \t ROC AUC: 0.89\n",
            "Epoch: 160 \t Loss: 0.29 \t ROC AUC: 0.88\n",
            "Epoch: 170 \t Loss: 0.29 \t ROC AUC: 0.84\n",
            "Epoch: 180 \t Loss: 0.28 \t ROC AUC: 0.85\n",
            "Epoch: 190 \t Loss: 0.27 \t ROC AUC: 0.84\n",
            "Epoch: 200 \t Loss: 0.27 \t ROC AUC: 0.86\n",
            "Epoch: 210 \t Loss: 0.27 \t ROC AUC: 0.84\n",
            "Epoch: 220 \t Loss: 0.26 \t ROC AUC: 0.85\n",
            "Epoch: 230 \t Loss: 0.25 \t ROC AUC: 0.85\n",
            "Epoch: 240 \t Loss: 0.25 \t ROC AUC: 0.86\n",
            "Epoch: 250 \t Loss: 0.24 \t ROC AUC: 0.84\n",
            "Epoch: 260 \t Loss: 0.24 \t ROC AUC: 0.85\n",
            "Epoch: 270 \t Loss: 0.23 \t ROC AUC: 0.85\n",
            "Epoch: 280 \t Loss: 0.23 \t ROC AUC: 0.84\n",
            "Epoch: 290 \t Loss: 0.23 \t ROC AUC: 0.87\n",
            "Epoch: 300 \t Loss: 0.22 \t ROC AUC: 0.86\n",
            "Epoch: 310 \t Loss: 0.22 \t ROC AUC: 0.86\n",
            "Epoch: 320 \t Loss: 0.21 \t ROC AUC: 0.86\n",
            "Epoch: 330 \t Loss: 0.21 \t ROC AUC: 0.87\n",
            "Epoch: 340 \t Loss: 0.21 \t ROC AUC: 0.87\n",
            "Epoch: 350 \t Loss: 0.20 \t ROC AUC: 0.87\n",
            "Epoch: 360 \t Loss: 0.20 \t ROC AUC: 0.89\n",
            "Epoch: 370 \t Loss: 0.20 \t ROC AUC: 0.88\n",
            "Epoch: 380 \t Loss: 0.19 \t ROC AUC: 0.87\n",
            "Epoch: 390 \t Loss: 0.19 \t ROC AUC: 0.88\n",
            "Epoch: 400 \t Loss: 0.19 \t ROC AUC: 0.87\n",
            "Epoch: 410 \t Loss: 0.19 \t ROC AUC: 0.87\n",
            "Epoch: 420 \t Loss: 0.19 \t ROC AUC: 0.88\n",
            "Epoch: 430 \t Loss: 0.19 \t ROC AUC: 0.87\n",
            "Epoch: 440 \t Loss: 0.18 \t ROC AUC: 0.87\n",
            "Epoch: 450 \t Loss: 0.18 \t ROC AUC: 0.87\n",
            "Epoch: 460 \t Loss: 0.18 \t ROC AUC: 0.88\n",
            "Epoch: 470 \t Loss: 0.18 \t ROC AUC: 0.88\n",
            "Epoch: 480 \t Loss: 0.18 \t ROC AUC: 0.88\n",
            "Epoch: 490 \t Loss: 0.18 \t ROC AUC: 0.88\n",
            "Epoch: 500 \t Loss: 0.18 \t ROC AUC: 0.88\n",
            "\n",
            "ROC: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset: wine"
      ],
      "metadata": {
        "id": "dstXtr-2tn8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# wine :: k=10 :: norm=false\n",
        "dim_h = graph.x.shape[1]\n",
        "model = GAE(graph.x.shape[1], dim_h, graph.x.shape[1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
        "\n",
        "best_roc = 0\n",
        "epochs = 500\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    embeddings = model(graph)\n",
        "    loss = loss_function(embeddings, graph)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            x_emb = model(graph)\n",
        "            x_emb = x_emb.detach().numpy()\n",
        "            loss = loss.detach().numpy()\n",
        "            roc_auc = evaluate(x, x_emb, y, plot = False)      \n",
        "            print('Epoch: %2d \\t Loss: %.2f \\t ROC AUC: %.2f' % (epoch, loss, roc_auc))\n",
        "            best_roc = max(best_roc, roc_auc)\n",
        "print('\\nROC: %.2f' % best_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGx9GzJWKApM",
        "outputId": "46100f2d-2bc7-44e9-869b-e1fb986a3d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 \t Loss: 594.55 \t ROC AUC: 1.00\n",
            "Epoch: 20 \t Loss: 309.24 \t ROC AUC: 1.00\n",
            "Epoch: 30 \t Loss: 183.57 \t ROC AUC: 1.00\n",
            "Epoch: 40 \t Loss: 143.84 \t ROC AUC: 1.00\n",
            "Epoch: 50 \t Loss: 107.23 \t ROC AUC: 0.85\n",
            "Epoch: 60 \t Loss: 84.22 \t ROC AUC: 0.92\n",
            "Epoch: 70 \t Loss: 79.54 \t ROC AUC: 0.92\n",
            "Epoch: 80 \t Loss: 79.52 \t ROC AUC: 0.84\n",
            "Epoch: 90 \t Loss: 90.30 \t ROC AUC: 0.84\n",
            "Epoch: 100 \t Loss: 115.33 \t ROC AUC: 0.84\n",
            "Epoch: 110 \t Loss: 84.34 \t ROC AUC: 0.87\n",
            "Epoch: 120 \t Loss: 80.58 \t ROC AUC: 0.87\n",
            "Epoch: 130 \t Loss: 85.29 \t ROC AUC: 0.79\n",
            "Epoch: 140 \t Loss: 73.47 \t ROC AUC: 0.88\n",
            "Epoch: 150 \t Loss: 75.22 \t ROC AUC: 0.78\n",
            "Epoch: 160 \t Loss: 78.13 \t ROC AUC: 0.73\n",
            "Epoch: 170 \t Loss: 72.66 \t ROC AUC: 0.83\n",
            "Epoch: 180 \t Loss: 71.00 \t ROC AUC: 0.77\n",
            "Epoch: 190 \t Loss: 72.99 \t ROC AUC: 0.85\n",
            "Epoch: 200 \t Loss: 71.91 \t ROC AUC: 0.71\n",
            "Epoch: 210 \t Loss: 78.12 \t ROC AUC: 0.77\n",
            "Epoch: 220 \t Loss: 60.06 \t ROC AUC: 0.84\n",
            "Epoch: 230 \t Loss: 64.81 \t ROC AUC: 0.88\n",
            "Epoch: 240 \t Loss: 71.01 \t ROC AUC: 0.91\n",
            "Epoch: 250 \t Loss: 71.93 \t ROC AUC: 0.83\n",
            "Epoch: 260 \t Loss: 61.22 \t ROC AUC: 0.91\n",
            "Epoch: 270 \t Loss: 64.44 \t ROC AUC: 0.84\n",
            "Epoch: 280 \t Loss: 61.47 \t ROC AUC: 0.90\n",
            "Epoch: 290 \t Loss: 74.86 \t ROC AUC: 0.84\n",
            "Epoch: 300 \t Loss: 54.28 \t ROC AUC: 0.90\n",
            "Epoch: 310 \t Loss: 59.48 \t ROC AUC: 0.92\n",
            "Epoch: 320 \t Loss: 57.57 \t ROC AUC: 0.89\n",
            "Epoch: 330 \t Loss: 60.68 \t ROC AUC: 0.87\n",
            "Epoch: 340 \t Loss: 66.59 \t ROC AUC: 0.79\n",
            "Epoch: 350 \t Loss: 49.49 \t ROC AUC: 0.87\n",
            "Epoch: 360 \t Loss: 76.32 \t ROC AUC: 0.82\n",
            "Epoch: 370 \t Loss: 76.46 \t ROC AUC: 0.80\n",
            "Epoch: 380 \t Loss: 49.04 \t ROC AUC: 0.76\n",
            "Epoch: 390 \t Loss: 67.02 \t ROC AUC: 0.88\n",
            "Epoch: 400 \t Loss: 69.12 \t ROC AUC: 0.89\n",
            "Epoch: 410 \t Loss: 57.96 \t ROC AUC: 0.91\n",
            "Epoch: 420 \t Loss: 50.57 \t ROC AUC: 0.71\n",
            "Epoch: 430 \t Loss: 54.79 \t ROC AUC: 0.83\n",
            "Epoch: 440 \t Loss: 52.85 \t ROC AUC: 0.93\n",
            "Epoch: 450 \t Loss: 48.57 \t ROC AUC: 0.88\n",
            "Epoch: 460 \t Loss: 51.24 \t ROC AUC: 0.93\n",
            "Epoch: 470 \t Loss: 50.73 \t ROC AUC: 0.94\n",
            "Epoch: 480 \t Loss: 45.75 \t ROC AUC: 0.68\n",
            "Epoch: 490 \t Loss: 64.12 \t ROC AUC: 0.90\n",
            "Epoch: 500 \t Loss: 49.53 \t ROC AUC: 0.75\n",
            "\n",
            "ROC: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset: pima"
      ],
      "metadata": {
        "id": "bal-ln_wtuid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pima :: k=20 :: norm=false\n",
        "dim_h = graph.x.shape[1]\n",
        "model = GAE(graph.x.shape[1], dim_h, graph.x.shape[1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.005)\n",
        "\n",
        "best_roc = 0\n",
        "epochs = 500\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    embeddings = model(graph)\n",
        "    loss = loss_function(embeddings, graph)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            x_emb = model(graph)\n",
        "            x_emb = x_emb.detach().numpy()\n",
        "            loss = loss.detach().numpy()\n",
        "            roc_auc = evaluate(x, x_emb, y, plot = False)      \n",
        "            print('Epoch: %2d \\t Loss: %.2f \\t ROC AUC: %.2f' % (epoch, loss, roc_auc))\n",
        "            best_roc = max(best_roc, roc_auc)\n",
        "print('\\nROC: %.2f' % best_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0ujx9biKFXg",
        "outputId": "3d5c0236-ee4d-4e7d-adcc-5429bb6ab34b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 \t Loss: 172.89 \t ROC AUC: 0.77\n",
            "Epoch: 20 \t Loss: 135.48 \t ROC AUC: 0.74\n",
            "Epoch: 30 \t Loss: 108.29 \t ROC AUC: 0.68\n",
            "Epoch: 40 \t Loss: 93.09 \t ROC AUC: 0.64\n",
            "Epoch: 50 \t Loss: 85.32 \t ROC AUC: 0.67\n",
            "Epoch: 60 \t Loss: 78.36 \t ROC AUC: 0.71\n",
            "Epoch: 70 \t Loss: 70.04 \t ROC AUC: 0.67\n",
            "Epoch: 80 \t Loss: 61.86 \t ROC AUC: 0.67\n",
            "Epoch: 90 \t Loss: 54.20 \t ROC AUC: 0.63\n",
            "Epoch: 100 \t Loss: 50.90 \t ROC AUC: 0.64\n",
            "Epoch: 110 \t Loss: 45.50 \t ROC AUC: 0.62\n",
            "Epoch: 120 \t Loss: 42.27 \t ROC AUC: 0.61\n",
            "Epoch: 130 \t Loss: 44.64 \t ROC AUC: 0.62\n",
            "Epoch: 140 \t Loss: 43.26 \t ROC AUC: 0.61\n",
            "Epoch: 150 \t Loss: 43.25 \t ROC AUC: 0.61\n",
            "Epoch: 160 \t Loss: 40.63 \t ROC AUC: 0.62\n",
            "Epoch: 170 \t Loss: 41.32 \t ROC AUC: 0.61\n",
            "Epoch: 180 \t Loss: 40.35 \t ROC AUC: 0.63\n",
            "Epoch: 190 \t Loss: 39.34 \t ROC AUC: 0.66\n",
            "Epoch: 200 \t Loss: 40.40 \t ROC AUC: 0.67\n",
            "Epoch: 210 \t Loss: 38.95 \t ROC AUC: 0.66\n",
            "Epoch: 220 \t Loss: 39.32 \t ROC AUC: 0.62\n",
            "Epoch: 230 \t Loss: 40.01 \t ROC AUC: 0.57\n",
            "Epoch: 240 \t Loss: 40.64 \t ROC AUC: 0.60\n",
            "Epoch: 250 \t Loss: 39.52 \t ROC AUC: 0.61\n",
            "Epoch: 260 \t Loss: 38.59 \t ROC AUC: 0.59\n",
            "Epoch: 270 \t Loss: 39.36 \t ROC AUC: 0.62\n",
            "Epoch: 280 \t Loss: 36.46 \t ROC AUC: 0.62\n",
            "Epoch: 290 \t Loss: 38.15 \t ROC AUC: 0.61\n",
            "Epoch: 300 \t Loss: 36.41 \t ROC AUC: 0.60\n",
            "Epoch: 310 \t Loss: 35.23 \t ROC AUC: 0.57\n",
            "Epoch: 320 \t Loss: 34.50 \t ROC AUC: 0.59\n",
            "Epoch: 330 \t Loss: 35.75 \t ROC AUC: 0.65\n",
            "Epoch: 340 \t Loss: 34.38 \t ROC AUC: 0.67\n",
            "Epoch: 350 \t Loss: 34.82 \t ROC AUC: 0.60\n",
            "Epoch: 360 \t Loss: 33.44 \t ROC AUC: 0.60\n",
            "Epoch: 370 \t Loss: 36.03 \t ROC AUC: 0.57\n",
            "Epoch: 380 \t Loss: 34.57 \t ROC AUC: 0.61\n",
            "Epoch: 390 \t Loss: 33.65 \t ROC AUC: 0.58\n",
            "Epoch: 400 \t Loss: 33.23 \t ROC AUC: 0.60\n",
            "Epoch: 410 \t Loss: 34.71 \t ROC AUC: 0.58\n",
            "Epoch: 420 \t Loss: 34.85 \t ROC AUC: 0.61\n",
            "Epoch: 430 \t Loss: 34.76 \t ROC AUC: 0.58\n",
            "Epoch: 440 \t Loss: 34.14 \t ROC AUC: 0.61\n",
            "Epoch: 450 \t Loss: 33.77 \t ROC AUC: 0.64\n",
            "Epoch: 460 \t Loss: 33.86 \t ROC AUC: 0.58\n",
            "Epoch: 470 \t Loss: 33.82 \t ROC AUC: 0.56\n",
            "Epoch: 480 \t Loss: 31.11 \t ROC AUC: 0.56\n",
            "Epoch: 490 \t Loss: 34.00 \t ROC AUC: 0.61\n",
            "Epoch: 500 \t Loss: 34.65 \t ROC AUC: 0.55\n",
            "\n",
            "ROC: 0.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset: glass"
      ],
      "metadata": {
        "id": "NM1ZqNrrtw5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# glass :: k=20 :: norm=false\n",
        "dim_h = graph.x.shape[1]\n",
        "model = GAE(graph.x.shape[1], dim_h, graph.x.shape[1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
        "\n",
        "best_roc = 0\n",
        "epochs = 500\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    embeddings = model(graph)\n",
        "    loss = loss_function(embeddings, graph)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            x_emb = model(graph)\n",
        "            x_emb = x_emb.detach().numpy()\n",
        "            loss = loss.detach().numpy()\n",
        "            roc_auc = evaluate(x, x_emb, y, plot = False)      \n",
        "            print('Epoch: %2d \\t Loss: %.2f \\t ROC AUC: %.2f' % (epoch, loss, roc_auc))\n",
        "            best_roc = max(best_roc, roc_auc)\n",
        "print('\\nROC: %.2f' % best_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1uTgCngQDIj",
        "outputId": "c0953d18-6ad7-43fe-9b44-7f26b6038856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 \t Loss: 24.62 \t ROC AUC: 0.35\n",
            "Epoch: 20 \t Loss: 13.47 \t ROC AUC: 0.62\n",
            "Epoch: 30 \t Loss: 9.84 \t ROC AUC: 0.43\n",
            "Epoch: 40 \t Loss: 10.16 \t ROC AUC: 0.65\n",
            "Epoch: 50 \t Loss: 9.67 \t ROC AUC: 0.83\n",
            "Epoch: 60 \t Loss: 5.98 \t ROC AUC: 0.80\n",
            "Epoch: 70 \t Loss: 7.86 \t ROC AUC: 0.88\n",
            "Epoch: 80 \t Loss: 9.34 \t ROC AUC: 0.83\n",
            "Epoch: 90 \t Loss: 10.16 \t ROC AUC: 0.85\n",
            "Epoch: 100 \t Loss: 10.97 \t ROC AUC: 0.96\n",
            "Epoch: 110 \t Loss: 9.27 \t ROC AUC: 0.84\n",
            "Epoch: 120 \t Loss: 5.71 \t ROC AUC: 0.59\n",
            "Epoch: 130 \t Loss: 9.45 \t ROC AUC: 0.94\n",
            "Epoch: 140 \t Loss: 7.65 \t ROC AUC: 0.95\n",
            "Epoch: 150 \t Loss: 7.68 \t ROC AUC: 0.94\n",
            "Epoch: 160 \t Loss: 7.22 \t ROC AUC: 0.83\n",
            "Epoch: 170 \t Loss: 5.13 \t ROC AUC: 0.82\n",
            "Epoch: 180 \t Loss: 6.17 \t ROC AUC: 0.79\n",
            "Epoch: 190 \t Loss: 6.03 \t ROC AUC: 0.82\n",
            "Epoch: 200 \t Loss: 6.33 \t ROC AUC: 0.83\n",
            "Epoch: 210 \t Loss: 4.74 \t ROC AUC: 0.71\n",
            "Epoch: 220 \t Loss: 6.14 \t ROC AUC: 0.75\n",
            "Epoch: 230 \t Loss: 9.74 \t ROC AUC: 0.79\n",
            "Epoch: 240 \t Loss: 6.42 \t ROC AUC: 0.84\n",
            "Epoch: 250 \t Loss: 7.96 \t ROC AUC: 0.78\n",
            "Epoch: 260 \t Loss: 7.43 \t ROC AUC: 0.75\n",
            "Epoch: 270 \t Loss: 5.11 \t ROC AUC: 0.56\n",
            "Epoch: 280 \t Loss: 8.35 \t ROC AUC: 0.47\n",
            "Epoch: 290 \t Loss: 5.48 \t ROC AUC: 0.90\n",
            "Epoch: 300 \t Loss: 6.04 \t ROC AUC: 0.69\n",
            "Epoch: 310 \t Loss: 5.05 \t ROC AUC: 0.57\n",
            "Epoch: 320 \t Loss: 6.39 \t ROC AUC: 0.45\n",
            "Epoch: 330 \t Loss: 6.95 \t ROC AUC: 0.80\n",
            "Epoch: 340 \t Loss: 4.34 \t ROC AUC: 0.74\n",
            "Epoch: 350 \t Loss: 6.90 \t ROC AUC: 0.67\n",
            "Epoch: 360 \t Loss: 4.35 \t ROC AUC: 0.70\n",
            "Epoch: 370 \t Loss: 6.51 \t ROC AUC: 0.86\n",
            "Epoch: 380 \t Loss: 6.01 \t ROC AUC: 0.74\n",
            "Epoch: 390 \t Loss: 7.23 \t ROC AUC: 0.84\n",
            "Epoch: 400 \t Loss: 6.75 \t ROC AUC: 0.80\n",
            "Epoch: 410 \t Loss: 8.01 \t ROC AUC: 0.79\n",
            "Epoch: 420 \t Loss: 5.32 \t ROC AUC: 0.26\n",
            "Epoch: 430 \t Loss: 4.78 \t ROC AUC: 0.70\n",
            "Epoch: 440 \t Loss: 5.54 \t ROC AUC: 0.50\n",
            "Epoch: 450 \t Loss: 4.56 \t ROC AUC: 0.82\n",
            "Epoch: 460 \t Loss: 8.46 \t ROC AUC: 0.77\n",
            "Epoch: 470 \t Loss: 7.73 \t ROC AUC: 0.41\n",
            "Epoch: 480 \t Loss: 7.67 \t ROC AUC: 0.72\n",
            "Epoch: 490 \t Loss: 8.67 \t ROC AUC: 0.22\n",
            "Epoch: 500 \t Loss: 6.80 \t ROC AUC: 0.79\n",
            "\n",
            "ROC: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset: vertebral"
      ],
      "metadata": {
        "id": "CfVqLMshtzCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vertebral :: k=10 :: norm=false\n",
        "dim_h = graph.x.shape[1]\n",
        "model = GAE(graph.x.shape[1], dim_h, graph.x.shape[1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
        "\n",
        "best_roc = 0\n",
        "epochs = 200\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    embeddings = model(graph)\n",
        "    loss = loss_function(embeddings, graph)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            x_emb = model(graph)\n",
        "            x_emb = x_emb.detach().numpy()\n",
        "            loss = loss.detach().numpy()\n",
        "            roc_auc = evaluate(x, x_emb, y, plot = False)      \n",
        "            print('Epoch: %2d \\t Loss: %.2f \\t ROC AUC: %.2f' % (epoch, loss, roc_auc))\n",
        "            best_roc = max(best_roc, roc_auc)\n",
        "print('\\nROC: %.2f' % best_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXFfXb8WScSx",
        "outputId": "880849f4-8c90-4685-98db-e897bd22823e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 \t Loss: 148.37 \t ROC AUC: 0.63\n",
            "Epoch: 20 \t Loss: 102.44 \t ROC AUC: 0.62\n",
            "Epoch: 30 \t Loss: 65.82 \t ROC AUC: 0.84\n",
            "Epoch: 40 \t Loss: 48.65 \t ROC AUC: 0.33\n",
            "Epoch: 50 \t Loss: 42.38 \t ROC AUC: 0.64\n",
            "Epoch: 60 \t Loss: 41.17 \t ROC AUC: 0.51\n",
            "Epoch: 70 \t Loss: 35.17 \t ROC AUC: 0.38\n",
            "Epoch: 80 \t Loss: 34.45 \t ROC AUC: 0.43\n",
            "Epoch: 90 \t Loss: 36.58 \t ROC AUC: 0.49\n",
            "Epoch: 100 \t Loss: 36.43 \t ROC AUC: 0.39\n",
            "Epoch: 110 \t Loss: 34.24 \t ROC AUC: 0.56\n",
            "Epoch: 120 \t Loss: 34.40 \t ROC AUC: 0.43\n",
            "Epoch: 130 \t Loss: 35.06 \t ROC AUC: 0.40\n",
            "Epoch: 140 \t Loss: 34.74 \t ROC AUC: 0.64\n",
            "Epoch: 150 \t Loss: 31.72 \t ROC AUC: 0.31\n",
            "Epoch: 160 \t Loss: 36.95 \t ROC AUC: 0.37\n",
            "Epoch: 170 \t Loss: 33.85 \t ROC AUC: 0.39\n",
            "Epoch: 180 \t Loss: 32.86 \t ROC AUC: 0.56\n",
            "Epoch: 190 \t Loss: 35.47 \t ROC AUC: 0.33\n",
            "Epoch: 200 \t Loss: 32.95 \t ROC AUC: 0.39\n",
            "\n",
            "ROC: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset: ionosphere"
      ],
      "metadata": {
        "id": "KhXOzTrpt2Iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ionosphere :: k=10 :: norm=false\n",
        "dim_h = graph.x.shape[1]\n",
        "model = GAE(graph.x.shape[1], dim_h, graph.x.shape[1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
        "\n",
        "best_roc = 0\n",
        "epochs = 500\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    embeddings = model(graph)\n",
        "    loss = loss_function(embeddings, graph)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            x_emb = model(graph)\n",
        "            x_emb = x_emb.detach().numpy()\n",
        "            loss = loss.detach().numpy()\n",
        "            roc_auc = evaluate(x, x_emb, y, plot = False)      \n",
        "            print('Epoch: %2d \\t Loss: %.2f \\t ROC AUC: %.2f' % (epoch, loss, roc_auc))\n",
        "            best_roc = max(best_roc, roc_auc)\n",
        "print('\\nROC: %.2f' % best_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwisaM6fVWVb",
        "outputId": "ce12f610-2ce2-4b48-e6b2-5fd5c762b0d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 \t Loss: 2.90 \t ROC AUC: 0.73\n",
            "Epoch: 20 \t Loss: 2.38 \t ROC AUC: 0.85\n",
            "Epoch: 30 \t Loss: 2.07 \t ROC AUC: 0.88\n",
            "Epoch: 40 \t Loss: 1.92 \t ROC AUC: 0.91\n",
            "Epoch: 50 \t Loss: 1.71 \t ROC AUC: 0.94\n",
            "Epoch: 60 \t Loss: 1.69 \t ROC AUC: 0.95\n",
            "Epoch: 70 \t Loss: 1.60 \t ROC AUC: 0.95\n",
            "Epoch: 80 \t Loss: 1.57 \t ROC AUC: 0.95\n",
            "Epoch: 90 \t Loss: 1.64 \t ROC AUC: 0.95\n",
            "Epoch: 100 \t Loss: 1.54 \t ROC AUC: 0.95\n",
            "Epoch: 110 \t Loss: 1.49 \t ROC AUC: 0.95\n",
            "Epoch: 120 \t Loss: 1.51 \t ROC AUC: 0.95\n",
            "Epoch: 130 \t Loss: 1.46 \t ROC AUC: 0.95\n",
            "Epoch: 140 \t Loss: 1.43 \t ROC AUC: 0.95\n",
            "Epoch: 150 \t Loss: 1.41 \t ROC AUC: 0.95\n",
            "Epoch: 160 \t Loss: 1.39 \t ROC AUC: 0.95\n",
            "Epoch: 170 \t Loss: 1.37 \t ROC AUC: 0.96\n",
            "Epoch: 180 \t Loss: 1.35 \t ROC AUC: 0.95\n",
            "Epoch: 190 \t Loss: 1.33 \t ROC AUC: 0.96\n",
            "Epoch: 200 \t Loss: 1.32 \t ROC AUC: 0.96\n",
            "Epoch: 210 \t Loss: 1.29 \t ROC AUC: 0.96\n",
            "Epoch: 220 \t Loss: 1.28 \t ROC AUC: 0.96\n",
            "Epoch: 230 \t Loss: 1.26 \t ROC AUC: 0.96\n",
            "Epoch: 240 \t Loss: 1.24 \t ROC AUC: 0.96\n",
            "Epoch: 250 \t Loss: 1.23 \t ROC AUC: 0.96\n",
            "Epoch: 260 \t Loss: 1.21 \t ROC AUC: 0.96\n",
            "Epoch: 270 \t Loss: 1.20 \t ROC AUC: 0.95\n",
            "Epoch: 280 \t Loss: 1.19 \t ROC AUC: 0.95\n",
            "Epoch: 290 \t Loss: 1.19 \t ROC AUC: 0.95\n",
            "Epoch: 300 \t Loss: 1.18 \t ROC AUC: 0.95\n",
            "Epoch: 310 \t Loss: 1.17 \t ROC AUC: 0.95\n",
            "Epoch: 320 \t Loss: 1.16 \t ROC AUC: 0.95\n",
            "Epoch: 330 \t Loss: 1.15 \t ROC AUC: 0.95\n",
            "Epoch: 340 \t Loss: 1.14 \t ROC AUC: 0.95\n",
            "Epoch: 350 \t Loss: 1.13 \t ROC AUC: 0.95\n",
            "Epoch: 360 \t Loss: 1.14 \t ROC AUC: 0.95\n",
            "Epoch: 370 \t Loss: 1.13 \t ROC AUC: 0.95\n",
            "Epoch: 380 \t Loss: 1.12 \t ROC AUC: 0.95\n",
            "Epoch: 390 \t Loss: 1.12 \t ROC AUC: 0.94\n",
            "Epoch: 400 \t Loss: 1.11 \t ROC AUC: 0.95\n",
            "Epoch: 410 \t Loss: 1.10 \t ROC AUC: 0.95\n",
            "Epoch: 420 \t Loss: 1.10 \t ROC AUC: 0.95\n",
            "Epoch: 430 \t Loss: 1.10 \t ROC AUC: 0.95\n",
            "Epoch: 440 \t Loss: 1.10 \t ROC AUC: 0.94\n",
            "Epoch: 450 \t Loss: 1.10 \t ROC AUC: 0.94\n",
            "Epoch: 460 \t Loss: 1.08 \t ROC AUC: 0.94\n",
            "Epoch: 470 \t Loss: 1.08 \t ROC AUC: 0.94\n",
            "Epoch: 480 \t Loss: 1.08 \t ROC AUC: 0.94\n",
            "Epoch: 490 \t Loss: 1.07 \t ROC AUC: 0.94\n",
            "Epoch: 500 \t Loss: 1.07 \t ROC AUC: 0.94\n",
            "\n",
            "ROC: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset: vowels"
      ],
      "metadata": {
        "id": "Jo55bO-_t6TU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vowels :: k=40 :: norm=false\n",
        "dim_h = graph.x.shape[1]\n",
        "model = GAE(graph.x.shape[1], dim_h, graph.x.shape[1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
        "\n",
        "best_roc = 0\n",
        "epochs = 500\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    embeddings = model(graph)\n",
        "    loss = loss_function(embeddings, graph)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            x_emb = model(graph)\n",
        "            x_emb = x_emb.detach().numpy()\n",
        "            loss = loss.detach().numpy()\n",
        "            roc_auc = evaluate(x, x_emb, y, plot = False)      \n",
        "            print('Epoch: %2d \\t Loss: %.2f \\t ROC AUC: %.2f' % (epoch, loss, roc_auc))\n",
        "            best_roc = max(best_roc, roc_auc)\n",
        "print('\\nROC: %.2f' % best_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b52a4d07-737d-40dd-a4f1-ad105523d193",
        "id": "1dptOt2DfbuG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 \t Loss: 3.85 \t ROC AUC: 0.57\n",
            "Epoch: 20 \t Loss: 3.41 \t ROC AUC: 0.62\n",
            "Epoch: 30 \t Loss: 3.36 \t ROC AUC: 0.63\n",
            "Epoch: 40 \t Loss: 3.29 \t ROC AUC: 0.64\n",
            "Epoch: 50 \t Loss: 3.23 \t ROC AUC: 0.65\n",
            "Epoch: 60 \t Loss: 3.12 \t ROC AUC: 0.67\n",
            "Epoch: 70 \t Loss: 3.06 \t ROC AUC: 0.68\n",
            "Epoch: 80 \t Loss: 3.03 \t ROC AUC: 0.69\n",
            "Epoch: 90 \t Loss: 3.00 \t ROC AUC: 0.68\n",
            "Epoch: 100 \t Loss: 2.98 \t ROC AUC: 0.69\n",
            "Epoch: 110 \t Loss: 2.97 \t ROC AUC: 0.68\n",
            "Epoch: 120 \t Loss: 2.96 \t ROC AUC: 0.68\n",
            "Epoch: 130 \t Loss: 2.94 \t ROC AUC: 0.69\n",
            "Epoch: 140 \t Loss: 2.96 \t ROC AUC: 0.70\n",
            "Epoch: 150 \t Loss: 2.89 \t ROC AUC: 0.70\n",
            "Epoch: 160 \t Loss: 2.90 \t ROC AUC: 0.71\n",
            "Epoch: 170 \t Loss: 2.84 \t ROC AUC: 0.71\n",
            "Epoch: 180 \t Loss: 2.86 \t ROC AUC: 0.72\n",
            "Epoch: 190 \t Loss: 2.72 \t ROC AUC: 0.75\n",
            "Epoch: 200 \t Loss: 2.64 \t ROC AUC: 0.75\n",
            "Epoch: 210 \t Loss: 2.60 \t ROC AUC: 0.77\n",
            "Epoch: 220 \t Loss: 2.63 \t ROC AUC: 0.78\n",
            "Epoch: 230 \t Loss: 2.57 \t ROC AUC: 0.79\n",
            "Epoch: 240 \t Loss: 2.55 \t ROC AUC: 0.79\n",
            "Epoch: 250 \t Loss: 2.54 \t ROC AUC: 0.79\n",
            "Epoch: 260 \t Loss: 2.46 \t ROC AUC: 0.80\n",
            "Epoch: 270 \t Loss: 2.44 \t ROC AUC: 0.80\n",
            "Epoch: 280 \t Loss: 2.39 \t ROC AUC: 0.83\n",
            "Epoch: 290 \t Loss: 2.36 \t ROC AUC: 0.86\n",
            "Epoch: 300 \t Loss: 2.36 \t ROC AUC: 0.87\n",
            "Epoch: 310 \t Loss: 2.30 \t ROC AUC: 0.89\n",
            "Epoch: 320 \t Loss: 2.26 \t ROC AUC: 0.88\n",
            "Epoch: 330 \t Loss: 2.21 \t ROC AUC: 0.89\n",
            "Epoch: 340 \t Loss: 2.24 \t ROC AUC: 0.89\n",
            "Epoch: 350 \t Loss: 2.21 \t ROC AUC: 0.89\n",
            "Epoch: 360 \t Loss: 2.16 \t ROC AUC: 0.89\n",
            "Epoch: 370 \t Loss: 2.08 \t ROC AUC: 0.90\n",
            "Epoch: 380 \t Loss: 2.15 \t ROC AUC: 0.91\n",
            "Epoch: 390 \t Loss: 2.08 \t ROC AUC: 0.91\n",
            "Epoch: 400 \t Loss: 2.06 \t ROC AUC: 0.91\n",
            "Epoch: 410 \t Loss: 2.04 \t ROC AUC: 0.91\n",
            "Epoch: 420 \t Loss: 2.01 \t ROC AUC: 0.91\n",
            "Epoch: 430 \t Loss: 2.03 \t ROC AUC: 0.92\n",
            "Epoch: 440 \t Loss: 2.03 \t ROC AUC: 0.92\n",
            "Epoch: 450 \t Loss: 1.99 \t ROC AUC: 0.92\n",
            "Epoch: 460 \t Loss: 2.00 \t ROC AUC: 0.92\n",
            "Epoch: 470 \t Loss: 1.97 \t ROC AUC: 0.92\n",
            "Epoch: 480 \t Loss: 1.97 \t ROC AUC: 0.92\n",
            "Epoch: 490 \t Loss: 2.03 \t ROC AUC: 0.92\n",
            "Epoch: 500 \t Loss: 1.94 \t ROC AUC: 0.93\n",
            "\n",
            "ROC: 0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Continuation\n",
        "epochs = 500\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    embeddings = model(graph)\n",
        "    loss = loss_function(embeddings, graph)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            x_emb = model(graph)\n",
        "            x_emb = x_emb.detach().numpy()\n",
        "            loss = loss.detach().numpy()\n",
        "            roc_auc = evaluate(x, x_emb, y, plot = False)      \n",
        "            print('Epoch: %2d \\t Loss: %.2f \\t ROC AUC: %.2f' % (epoch+500, loss, roc_auc))\n",
        "            best_roc = max(best_roc, roc_auc)\n",
        "print('\\nROC: %.2f' % best_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be844999-d37b-4fb8-eeed-9df69a7a2d91",
        "id": "m0ox1bDefbuH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 510 \t Loss: 1.97 \t ROC AUC: 0.92\n",
            "Epoch: 520 \t Loss: 1.93 \t ROC AUC: 0.92\n",
            "Epoch: 530 \t Loss: 1.93 \t ROC AUC: 0.93\n",
            "Epoch: 540 \t Loss: 1.94 \t ROC AUC: 0.93\n",
            "Epoch: 550 \t Loss: 1.91 \t ROC AUC: 0.93\n",
            "Epoch: 560 \t Loss: 1.85 \t ROC AUC: 0.94\n",
            "Epoch: 570 \t Loss: 1.88 \t ROC AUC: 0.93\n",
            "Epoch: 580 \t Loss: 1.89 \t ROC AUC: 0.93\n",
            "Epoch: 590 \t Loss: 1.90 \t ROC AUC: 0.94\n",
            "Epoch: 600 \t Loss: 1.84 \t ROC AUC: 0.94\n",
            "Epoch: 610 \t Loss: 1.86 \t ROC AUC: 0.94\n",
            "Epoch: 620 \t Loss: 1.88 \t ROC AUC: 0.94\n",
            "Epoch: 630 \t Loss: 1.89 \t ROC AUC: 0.94\n",
            "Epoch: 640 \t Loss: 1.82 \t ROC AUC: 0.94\n",
            "Epoch: 650 \t Loss: 1.85 \t ROC AUC: 0.94\n",
            "Epoch: 660 \t Loss: 1.81 \t ROC AUC: 0.94\n",
            "Epoch: 670 \t Loss: 1.93 \t ROC AUC: 0.95\n",
            "Epoch: 680 \t Loss: 1.84 \t ROC AUC: 0.95\n",
            "Epoch: 690 \t Loss: 1.87 \t ROC AUC: 0.94\n",
            "Epoch: 700 \t Loss: 1.80 \t ROC AUC: 0.94\n",
            "Epoch: 710 \t Loss: 1.78 \t ROC AUC: 0.94\n",
            "Epoch: 720 \t Loss: 1.77 \t ROC AUC: 0.95\n",
            "Epoch: 730 \t Loss: 1.82 \t ROC AUC: 0.94\n",
            "Epoch: 740 \t Loss: 1.81 \t ROC AUC: 0.95\n",
            "Epoch: 750 \t Loss: 1.80 \t ROC AUC: 0.94\n",
            "Epoch: 760 \t Loss: 1.79 \t ROC AUC: 0.94\n",
            "Epoch: 770 \t Loss: 1.79 \t ROC AUC: 0.95\n",
            "Epoch: 780 \t Loss: 1.80 \t ROC AUC: 0.94\n",
            "Epoch: 790 \t Loss: 1.83 \t ROC AUC: 0.94\n",
            "Epoch: 800 \t Loss: 1.77 \t ROC AUC: 0.95\n",
            "Epoch: 810 \t Loss: 1.76 \t ROC AUC: 0.94\n",
            "Epoch: 820 \t Loss: 1.78 \t ROC AUC: 0.94\n",
            "Epoch: 830 \t Loss: 1.75 \t ROC AUC: 0.95\n",
            "Epoch: 840 \t Loss: 1.75 \t ROC AUC: 0.95\n",
            "Epoch: 850 \t Loss: 1.76 \t ROC AUC: 0.95\n",
            "Epoch: 860 \t Loss: 1.78 \t ROC AUC: 0.95\n",
            "Epoch: 870 \t Loss: 1.77 \t ROC AUC: 0.95\n",
            "Epoch: 880 \t Loss: 1.74 \t ROC AUC: 0.95\n",
            "Epoch: 890 \t Loss: 1.71 \t ROC AUC: 0.95\n",
            "Epoch: 900 \t Loss: 1.72 \t ROC AUC: 0.95\n",
            "Epoch: 910 \t Loss: 1.73 \t ROC AUC: 0.94\n",
            "Epoch: 920 \t Loss: 1.70 \t ROC AUC: 0.95\n",
            "Epoch: 930 \t Loss: 1.79 \t ROC AUC: 0.95\n",
            "Epoch: 940 \t Loss: 1.68 \t ROC AUC: 0.95\n",
            "Epoch: 950 \t Loss: 1.73 \t ROC AUC: 0.95\n",
            "Epoch: 960 \t Loss: 1.71 \t ROC AUC: 0.95\n",
            "Epoch: 970 \t Loss: 1.72 \t ROC AUC: 0.95\n",
            "Epoch: 980 \t Loss: 1.73 \t ROC AUC: 0.94\n",
            "Epoch: 990 \t Loss: 1.67 \t ROC AUC: 0.95\n",
            "Epoch: 1000 \t Loss: 1.69 \t ROC AUC: 0.94\n",
            "\n",
            "ROC: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset: letter"
      ],
      "metadata": {
        "id": "86ecTCDzt8wR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# letter :: k=40 :: norm=false\n",
        "dim_h = graph.x.shape[1]\n",
        "model = GAE(graph.x.shape[1], dim_h, graph.x.shape[1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
        "\n",
        "best_roc = 0\n",
        "epochs = 1000\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    embeddings = model(graph)\n",
        "    loss = loss_function(embeddings, graph)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            x_emb = model(graph)\n",
        "            x_emb = x_emb.detach().numpy()\n",
        "            loss = loss.detach().numpy()\n",
        "            roc_auc = evaluate(x, x_emb, y, plot = False)      \n",
        "            print('Epoch: %2d \\t Loss: %.2f \\t ROC AUC: %.2f' % (epoch, loss, roc_auc))\n",
        "            best_roc = max(best_roc, roc_auc)\n",
        "print('\\nROC: %.2f' % best_roc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vQ1zdWBZFNd",
        "outputId": "7f0bcd9c-540a-4f18-84b6-937ab8e3b925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 \t Loss: 18.73 \t ROC AUC: 0.39\n",
            "Epoch: 20 \t Loss: 13.60 \t ROC AUC: 0.46\n",
            "Epoch: 30 \t Loss: 12.22 \t ROC AUC: 0.66\n",
            "Epoch: 40 \t Loss: 11.72 \t ROC AUC: 0.76\n",
            "Epoch: 50 \t Loss: 10.35 \t ROC AUC: 0.75\n",
            "Epoch: 60 \t Loss: 10.09 \t ROC AUC: 0.77\n",
            "Epoch: 70 \t Loss: 9.67 \t ROC AUC: 0.81\n",
            "Epoch: 80 \t Loss: 9.48 \t ROC AUC: 0.83\n",
            "Epoch: 90 \t Loss: 9.40 \t ROC AUC: 0.85\n",
            "Epoch: 100 \t Loss: 8.63 \t ROC AUC: 0.86\n",
            "Epoch: 110 \t Loss: 8.59 \t ROC AUC: 0.84\n",
            "Epoch: 120 \t Loss: 8.33 \t ROC AUC: 0.85\n",
            "Epoch: 130 \t Loss: 8.40 \t ROC AUC: 0.85\n",
            "Epoch: 140 \t Loss: 8.46 \t ROC AUC: 0.84\n",
            "Epoch: 150 \t Loss: 8.44 \t ROC AUC: 0.86\n",
            "Epoch: 160 \t Loss: 8.29 \t ROC AUC: 0.85\n",
            "Epoch: 170 \t Loss: 8.04 \t ROC AUC: 0.85\n",
            "Epoch: 180 \t Loss: 8.05 \t ROC AUC: 0.87\n",
            "Epoch: 190 \t Loss: 7.75 \t ROC AUC: 0.84\n",
            "Epoch: 200 \t Loss: 7.67 \t ROC AUC: 0.85\n",
            "Epoch: 210 \t Loss: 7.74 \t ROC AUC: 0.85\n",
            "Epoch: 220 \t Loss: 7.61 \t ROC AUC: 0.87\n",
            "Epoch: 230 \t Loss: 7.62 \t ROC AUC: 0.88\n",
            "Epoch: 240 \t Loss: 8.28 \t ROC AUC: 0.85\n",
            "Epoch: 250 \t Loss: 7.60 \t ROC AUC: 0.87\n",
            "Epoch: 260 \t Loss: 7.18 \t ROC AUC: 0.86\n",
            "Epoch: 270 \t Loss: 7.32 \t ROC AUC: 0.88\n",
            "Epoch: 280 \t Loss: 7.77 \t ROC AUC: 0.87\n",
            "Epoch: 290 \t Loss: 7.53 \t ROC AUC: 0.88\n",
            "Epoch: 300 \t Loss: 6.86 \t ROC AUC: 0.87\n",
            "Epoch: 310 \t Loss: 7.21 \t ROC AUC: 0.87\n",
            "Epoch: 320 \t Loss: 6.81 \t ROC AUC: 0.89\n",
            "Epoch: 330 \t Loss: 6.81 \t ROC AUC: 0.88\n",
            "Epoch: 340 \t Loss: 6.83 \t ROC AUC: 0.89\n",
            "Epoch: 350 \t Loss: 6.72 \t ROC AUC: 0.89\n",
            "Epoch: 360 \t Loss: 6.68 \t ROC AUC: 0.88\n",
            "Epoch: 370 \t Loss: 6.79 \t ROC AUC: 0.90\n",
            "Epoch: 380 \t Loss: 6.64 \t ROC AUC: 0.89\n",
            "Epoch: 390 \t Loss: 6.62 \t ROC AUC: 0.89\n",
            "Epoch: 400 \t Loss: 6.70 \t ROC AUC: 0.89\n",
            "Epoch: 410 \t Loss: 6.61 \t ROC AUC: 0.89\n",
            "Epoch: 420 \t Loss: 6.83 \t ROC AUC: 0.89\n",
            "Epoch: 430 \t Loss: 6.67 \t ROC AUC: 0.89\n",
            "Epoch: 440 \t Loss: 6.59 \t ROC AUC: 0.90\n",
            "Epoch: 450 \t Loss: 6.44 \t ROC AUC: 0.88\n",
            "Epoch: 460 \t Loss: 6.38 \t ROC AUC: 0.90\n",
            "Epoch: 470 \t Loss: 6.64 \t ROC AUC: 0.89\n",
            "Epoch: 480 \t Loss: 6.17 \t ROC AUC: 0.90\n",
            "Epoch: 490 \t Loss: 6.08 \t ROC AUC: 0.89\n",
            "Epoch: 500 \t Loss: 6.04 \t ROC AUC: 0.88\n",
            "Epoch: 510 \t Loss: 6.12 \t ROC AUC: 0.90\n",
            "Epoch: 520 \t Loss: 6.07 \t ROC AUC: 0.90\n",
            "Epoch: 530 \t Loss: 6.15 \t ROC AUC: 0.89\n",
            "Epoch: 540 \t Loss: 6.06 \t ROC AUC: 0.90\n",
            "Epoch: 550 \t Loss: 5.89 \t ROC AUC: 0.89\n",
            "Epoch: 560 \t Loss: 5.80 \t ROC AUC: 0.91\n",
            "Epoch: 570 \t Loss: 5.90 \t ROC AUC: 0.90\n",
            "Epoch: 580 \t Loss: 5.84 \t ROC AUC: 0.90\n",
            "Epoch: 590 \t Loss: 5.71 \t ROC AUC: 0.90\n",
            "Epoch: 600 \t Loss: 5.68 \t ROC AUC: 0.90\n",
            "Epoch: 610 \t Loss: 5.73 \t ROC AUC: 0.90\n",
            "Epoch: 620 \t Loss: 5.69 \t ROC AUC: 0.90\n",
            "Epoch: 630 \t Loss: 5.68 \t ROC AUC: 0.90\n",
            "Epoch: 640 \t Loss: 5.63 \t ROC AUC: 0.91\n",
            "Epoch: 650 \t Loss: 5.62 \t ROC AUC: 0.91\n",
            "Epoch: 660 \t Loss: 5.70 \t ROC AUC: 0.91\n",
            "Epoch: 670 \t Loss: 5.71 \t ROC AUC: 0.90\n",
            "Epoch: 680 \t Loss: 5.52 \t ROC AUC: 0.89\n",
            "Epoch: 690 \t Loss: 5.65 \t ROC AUC: 0.90\n",
            "Epoch: 700 \t Loss: 5.50 \t ROC AUC: 0.90\n",
            "Epoch: 710 \t Loss: 5.84 \t ROC AUC: 0.90\n",
            "Epoch: 720 \t Loss: 5.48 \t ROC AUC: 0.90\n",
            "Epoch: 730 \t Loss: 5.45 \t ROC AUC: 0.90\n",
            "Epoch: 740 \t Loss: 5.59 \t ROC AUC: 0.91\n",
            "Epoch: 750 \t Loss: 5.56 \t ROC AUC: 0.91\n",
            "Epoch: 760 \t Loss: 5.36 \t ROC AUC: 0.90\n",
            "Epoch: 770 \t Loss: 5.34 \t ROC AUC: 0.90\n",
            "Epoch: 780 \t Loss: 5.26 \t ROC AUC: 0.90\n",
            "Epoch: 790 \t Loss: 5.28 \t ROC AUC: 0.90\n",
            "Epoch: 800 \t Loss: 5.60 \t ROC AUC: 0.90\n",
            "Epoch: 810 \t Loss: 5.40 \t ROC AUC: 0.90\n",
            "Epoch: 820 \t Loss: 5.27 \t ROC AUC: 0.90\n",
            "Epoch: 830 \t Loss: 5.23 \t ROC AUC: 0.90\n",
            "Epoch: 840 \t Loss: 5.33 \t ROC AUC: 0.90\n",
            "Epoch: 850 \t Loss: 5.26 \t ROC AUC: 0.90\n",
            "Epoch: 860 \t Loss: 5.21 \t ROC AUC: 0.90\n",
            "Epoch: 870 \t Loss: 5.22 \t ROC AUC: 0.90\n",
            "Epoch: 880 \t Loss: 5.12 \t ROC AUC: 0.90\n",
            "Epoch: 890 \t Loss: 5.15 \t ROC AUC: 0.90\n",
            "Epoch: 900 \t Loss: 5.09 \t ROC AUC: 0.90\n",
            "Epoch: 910 \t Loss: 5.14 \t ROC AUC: 0.91\n",
            "Epoch: 920 \t Loss: 5.15 \t ROC AUC: 0.90\n",
            "Epoch: 930 \t Loss: 5.10 \t ROC AUC: 0.90\n",
            "Epoch: 940 \t Loss: 5.02 \t ROC AUC: 0.90\n",
            "Epoch: 950 \t Loss: 5.03 \t ROC AUC: 0.90\n",
            "Epoch: 960 \t Loss: 5.11 \t ROC AUC: 0.90\n",
            "Epoch: 970 \t Loss: 4.99 \t ROC AUC: 0.90\n",
            "Epoch: 980 \t Loss: 4.89 \t ROC AUC: 0.90\n",
            "Epoch: 990 \t Loss: 4.95 \t ROC AUC: 0.90\n",
            "Epoch: 1000 \t Loss: 4.92 \t ROC AUC: 0.90\n",
            "\n",
            "ROC: 0.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_32xyQol0zDk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}